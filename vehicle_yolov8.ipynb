{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fc4e0f-4665-41ff-8ffb-41ede1d7a21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.set_device(0)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2429b17-ed81-44fa-a3b9-f2da7093bdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02918845-3a20-4cca-ae36-b4afac72f90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def processVideoTrackYolo(videoName, videoFolder, outputFolder = ''):\n",
    "    outputCSVFile = outputFolder + videoName + '-output.csv'\n",
    "    video_path = videoFolder + videoName\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    \n",
    "    \n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    output_path = outputFolder + videoName + '_output.mp4'\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "    track_history = defaultdict(lambda: [])\n",
    "    frame_number = 0\n",
    "    all_detections = []\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        success, frame = cap.read()\n",
    "    \n",
    "        if success:\n",
    "            results = model.track(frame, persist=True, classes = [2, 3, 5, 7])\n",
    "            frame_number += 1\n",
    "            if results[0].boxes.id is not None:\n",
    "                boxes = results[0].boxes.xywh.cpu()\n",
    "                track_ids = results[0].boxes.id.int().cpu().tolist()\n",
    "        \n",
    "                annotated_frame = results[0].plot()\n",
    "        \n",
    "                for box, track_id in zip(boxes, track_ids):\n",
    "                    x, y, w, h = box\n",
    "                    track = track_history[track_id]\n",
    "                    track.append((float(x), float(y)))\n",
    "                    if len(track) > 30:\n",
    "                        track.pop(0)\n",
    "        \n",
    "                    points = np.hstack(track).astype(np.int32).reshape((-1, 1, 2))\n",
    "                    cv2.polylines(annotated_frame, [points], isClosed=False, color=(255,170,29), thickness=15)\n",
    "        \n",
    "                finished_tracks = track_history.keys() - track_ids\n",
    "                for ft_id in finished_tracks:\n",
    "                    ft = track_history.pop(ft_id)\n",
    "                       \n",
    "                cv2.imshow(\"YOLOv8 Tracking Vehicles\", annotated_frame)\n",
    "\n",
    "                out.write(annotated_frame)\n",
    "\n",
    "                detections = results[0].summary(normalize=False, decimals=5)\n",
    "                \n",
    "                for detection in detections:\n",
    "                    detection['frame'] = frame_number\n",
    "                    detection['x1'] = detection['box']['x1']\n",
    "                    detection['y1'] = detection['box']['y1']\n",
    "                    detection['x2'] = detection['box']['x2']\n",
    "                    detection['y2'] = detection['box']['y2']\n",
    "                    del detection['box']\n",
    "                    all_detections.append(detection)\n",
    "                \n",
    "            \n",
    "            if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    df = pd.DataFrame(all_detections)\n",
    "    df.to_csv(outputCSVFile, index=False)\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(f\"Annotated video saved as {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e61cd3f-1375-481c-a871-1b824d7a37d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "testVideosFolder = '/media/rv/Disk 0/SST-ComputerVision/Cameras/Retry/check2rd/CrossCamera_cam5_cam8/'\n",
    "outputVehicleTrack= 'vehicle-track-csv/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfac9e3-2b27-4980-a022-a8baeff3a8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "##For small objects, lower-stride models typically fare better. That's because these models generally maintain more detail from the input image, which can be essential for detecting and correctly classifying small objects. Our YOLOv8s, YOLOv8m, or YOLOv8l models would be great for small objects detection.\n",
    "##For large objects, higher-stride models often work well. These models effectively sum up larger areas of the image, which can help them detect and classify large objects. In this case, the YOLOv8x and YOLOv8x6 models could be a better option.\n",
    "##For a mixed-size object detection or segmentation, a model with a mix of strides can often hit the sweet spot. This includes models like YOLOv8l6 or YOLOv8x6, which have additional P6 output with stride 64.\n",
    "\n",
    "model = YOLO('yolov8x.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4e8043-d6c8-42fd-80e6-7126f78729ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "processVideoTrackYolo(\"M24_cam5_8.avi\", testVideosFolder, outputVehicleTrack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8b9555-1c68-48c4-8950-274e0ca8ea72",
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle_videos = os.listdir(testVideosFolder)\n",
    "\n",
    "print(vehicle_videos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3dc3732-8fec-4537-b6b1-5706e3d76c51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for videoName in vehicle_videos[:2]:\n",
    "    print('processing: ' + videoName)\n",
    "    processVideoTrackYolo(videoName, testVideosFolder, outputVehicleTrack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81476fdc-4b71-4e56-99ee-133364e9fd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from datetime import timedelta\n",
    "\n",
    "def processVideoTrackYoloTextOnly(videoName, videoFolder, outputFolder = '', save_interval=100):\n",
    "    outputCSVFile = outputFolder + videoName + '-output.csv'\n",
    "    cacheCSVFile = outputFolder + videoName + '-cached-output.csv'\n",
    "    video_path = videoFolder + videoName\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    frame_number = 0\n",
    "    all_detections = []\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        success, frame = cap.read()\n",
    "    \n",
    "        if success:\n",
    "            results = model.track(frame, persist=True, classes = [2, 3, 5, 7])\n",
    "            frame_number += 1\n",
    "            millis = cap.get(cv2.CAP_PROP_POS_MSEC)\n",
    "            timestamp = str(timedelta(milliseconds=millis))\n",
    "            if results[0].boxes.id is not None:\n",
    "                detections = results[0].summary(normalize=False, decimals=5)\n",
    "                for detection in detections:\n",
    "                    detection['frame'] = frame_number\n",
    "                    detection['timestamp'] = timestamp\n",
    "                    detection['x1'] = detection['box']['x1']\n",
    "                    detection['y1'] = detection['box']['y1']\n",
    "                    detection['x2'] = detection['box']['x2']\n",
    "                    detection['y2'] = detection['box']['y2']\n",
    "                    del detection['box']\n",
    "                    all_detections.append(detection)\n",
    "\n",
    "            if frame_number % save_interval == 0:\n",
    "                df = pd.DataFrame(all_detections)\n",
    "                df.to_csv(cacheCSVFile, index=False)\n",
    "                print(f\"Cached results saved as {cacheCSVFile} at frame {frame_number}\")\n",
    "            \n",
    "                    \n",
    "            \n",
    "            if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    df = pd.DataFrame(all_detections)\n",
    "    df.to_csv(outputCSVFile, index=False)\n",
    "    cap.release()\n",
    "    print(f\"Results csv saved as {outputCSVFile}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad6c345",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from datetime import timedelta\n",
    "\n",
    "def processVideoTrackYoloCSV(videoName, videoFolder, outputFolder = '', save_interval=100):\n",
    "    outputCSVFile = outputFolder + videoName + '-output.csv'\n",
    "    cacheCSVFile = outputFolder + videoName + '-cached-output.csv'\n",
    "\n",
    "    video_path = videoFolder + videoName\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    \n",
    "    \n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    output_path = outputFolder + videoName + '_output.mp4'\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "    track_history = defaultdict(lambda: [])\n",
    "    frame_number = 0\n",
    "    all_detections = []\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        success, frame = cap.read()\n",
    "    \n",
    "        if success:\n",
    "            results = model.track(frame, persist=True, classes = [2, 3, 5, 7])\n",
    "            frame_number += 1\n",
    "            if results[0].boxes.id is not None:\n",
    "                boxes = results[0].boxes.xywh.cpu()\n",
    "                track_ids = results[0].boxes.id.int().cpu().tolist()\n",
    "        \n",
    "                annotated_frame = results[0].plot()\n",
    "        \n",
    "                for box, track_id in zip(boxes, track_ids):\n",
    "                    x, y, w, h = box\n",
    "                    track = track_history[track_id]\n",
    "                    track.append((float(x), float(y)))\n",
    "                    if len(track) > 30:\n",
    "                        track.pop(0)\n",
    "        \n",
    "                    points = np.hstack(track).astype(np.int32).reshape((-1, 1, 2))\n",
    "                    cv2.polylines(annotated_frame, [points], isClosed=False, color=(255,170,29), thickness=15)\n",
    "        \n",
    "                finished_tracks = track_history.keys() - track_ids\n",
    "                for ft_id in finished_tracks:\n",
    "                    ft = track_history.pop(ft_id)\n",
    "                       \n",
    "                cv2.imshow(\"YOLOv8 Tracking Vehicles\", annotated_frame)\n",
    "\n",
    "                out.write(annotated_frame)\n",
    "\n",
    "                detections = results[0].summary(normalize=False, decimals=5)\n",
    "                millis = cap.get(cv2.CAP_PROP_POS_MSEC)\n",
    "                timestamp = str(timedelta(milliseconds=millis))\n",
    "                \n",
    "                for detection in detections:\n",
    "                    detection['frame'] = frame_number\n",
    "                    detection['timestamp'] = timestamp\n",
    "                    detection['x1'] = detection['box']['x1']\n",
    "                    detection['y1'] = detection['box']['y1']\n",
    "                    detection['x2'] = detection['box']['x2']\n",
    "                    detection['y2'] = detection['box']['y2']\n",
    "                    del detection['box']\n",
    "                    all_detections.append(detection)\n",
    "\n",
    "            if frame_number % save_interval == 0:\n",
    "                df = pd.DataFrame(all_detections)\n",
    "                df.to_csv(cacheCSVFile, index=False)\n",
    "                print(f\"Cached results saved as {cacheCSVFile} at frame {frame_number}\")\n",
    "            \n",
    "                \n",
    "            \n",
    "            if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    df = pd.DataFrame(all_detections)\n",
    "    df.to_csv(outputCSVFile, index=False)\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(f\"Annotated video saved as {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c121592-9c24-42fd-8c94-72dfd2677813",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "vehicle_videos = os.listdir(testVideosFolder)\n",
    "\n",
    "print(vehicle_videos)\n",
    "\n",
    "for videoName in vehicle_videos[:2]:\n",
    "    print('processing: ' + videoName)\n",
    "    processVideoTrackYoloTextOnly(videoName, testVideosFolder, outputVehicleTrack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345ceba7-dfed-4f6f-8f37-59d5c425d06d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "processVideoTrackYoloTextOnly(\"M9_cam7_4.avi\", testVideosFolder, outputVehicleTrack, save_interval=102)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5375e27-2260-4c87-91a6-407c192bcfb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "orangeVehFolder = '/media/rv/Disk 0/SST-ComputerVision/Cameras/Orange/veh-cams-in-one/'\n",
    "orange_vehicle_videos = os.listdir(orangeVehFolder)\n",
    "outputVehicleTrack= 'vehicle-track-csv/'\n",
    "\n",
    "print(orange_vehicle_videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36dd01a-998b-47d7-a794-83e692bfaea6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "for videoName in orange_vehicle_videos:\n",
    "    print('processing: ' + videoName)\n",
    "    model = YOLO('yolov8x.pt')\n",
    "    processVideoTrackYoloTextOnly(videoName, orangeVehFolder, outputVehicleTrack, save_interval=33333)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7463aa39",
   "metadata": {},
   "outputs": [],
   "source": [
    "orangeVehFolder = '/Users/rockr/OneDrive - University of Central Florida/ucf transportation/code/vehicle-computer-vision-csv/orange/'\n",
    "orange_vehicle_videos = os.listdir(orangeVehFolder)\n",
    "outputVehicleTrack= '/Users/rockr/OneDrive - University of Central Florida/ucf transportation/code/vehicle-computer-vision-csv/vehicle-track-csv/'\n",
    "\n",
    "print(orange_vehicle_videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cff6184-1a6f-4d23-ab8f-10f987047252",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "for videoName in orange_vehicle_videos:\n",
    "    print('processing: ' + videoName)\n",
    "    model = YOLO('yolov8x.pt')\n",
    "    processVideoTrackYoloCSV(videoName, orangeVehFolder, outputVehicleTrack, save_interval=63333)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3f406d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "for videoName in orange_vehicle_videos:\n",
    "    print('processing: ' + videoName)\n",
    "    model = YOLO('yolov8x.pt')\n",
    "    processVideoTrackYoloTextOnly(videoName, orangeVehFolder, outputVehicleTrack, save_interval=63333)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8555c10",
   "metadata": {},
   "source": [
    "### Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820c3494",
   "metadata": {},
   "outputs": [],
   "source": [
    "from video_processing import processVideoTrackYoloCSV\n",
    "\n",
    "processVideoTrackYoloCSV(videoName, orangeVehFolder, outputVehicleTrack, save_interval=10000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yologpu1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
